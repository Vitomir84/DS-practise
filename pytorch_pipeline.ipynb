{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.cuda import amp\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "import timm\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'folds' : 5,\n",
    "    'seed' : 872,\n",
    "    'img_size' : 224,\n",
    "    'model': 'efficientnet_b0',\n",
    "    'epochs' : 10, \n",
    "    'train_bs': 10,\n",
    "    'val_bs': 10,\n",
    "    'lr': 1e-3,\n",
    "    'amp': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelData(Dataset):\n",
    "    \n",
    "    def __init__(self, df: pd.DataFrame, train_augmentation = None, val_augmentation = None, train: bool = False, val: bool = False,):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.train = train\n",
    "        self.val = val\n",
    "        self.train_augmentation = train_augmentation\n",
    "        self.val_augmentation = val_augmentation\n",
    "        self.path = 'data/train/train/'\n",
    "        \n",
    "    def _load_image(self, idx):\n",
    "        path= self.path + self.df.iloc[idx]['image_name'] + '.jpg'\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        return img\n",
    "    \n",
    "    def _augment(self, img, fn):\n",
    "        transformed = fn(image=img)\n",
    "        transformed_image = transformed[\"image\"]\n",
    "        \n",
    "        return transformed_image\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = self._load_image(idx)\n",
    "        \n",
    "        if self.train:\n",
    "            img = self._augment(img, self.train_augmentation)\n",
    "            return img, self.df.iloc[idx]['target']\n",
    "        if self.val:\n",
    "            img = self._augment(img, self.val_augmentation)\n",
    "            return img, self.df.iloc[idx]['target']\n",
    "        \n",
    "        return img\n",
    "        \n",
    "    def __len__(self, ):\n",
    "        return len(self.df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train_concat.csv')\n",
    "train_df = train_df.iloc[:len(train_df)//2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_img(image):\n",
    "    cv2.namedWindow('Display', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('Display', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acc(z, y):\n",
    "    \n",
    "    out = np.where(z > .5, 1, 0)\n",
    "    \n",
    "    tp = out-y\n",
    "    return (tp[tp == 0].shape[0])/y.shape[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optim, criterion, scheduler,train_loader, val_loader, fold):\n",
    "    \n",
    "    if CFG['amp']:\n",
    "        scaler = amp.GradScaler()\n",
    "    \n",
    "    for i in range(1, CFG['epochs'] + 1):\n",
    "        \n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        batch_acc = []\n",
    "        best_val = 0\n",
    "        \n",
    "        \n",
    "        \n",
    "        for x, y in train_loader:\n",
    "            x = x.to(device).type(torch.float32)\n",
    "            y = y.to(device).type(torch.float32)\n",
    "            optim.zero_grad()\n",
    "            \n",
    "            if CFG['amp']:\n",
    "                \n",
    "                with amp.autocast():\n",
    "                    z = model(x)\n",
    "                    loss = criterion(z.squeeze(-1), y)\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optim)\n",
    "                scaler.update()                \n",
    "            else:\n",
    "                \n",
    "                z = model(x)\n",
    "                loss = criterion(z.squeeze(-1), y)\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            batch_acc.append(calc_acc(torch.sigmoid(z.squeeze(-1)).detach().cpu().numpy(), y.detach().cpu().numpy()))\n",
    "            \n",
    "\n",
    "        acc = np.mean(batch_acc)\n",
    "        \n",
    "        print(\"loss is %.3f and accuracy is %.3f\" %(epoch_loss, acc))\n",
    "        \n",
    "        val_auc = validate(model, criterion, val_loader)\n",
    "        scheduler.step(val_auc)\n",
    "        \n",
    "        if val_auc >= best_val:\n",
    "            best_val = val_auc\n",
    "            save_model(model, 'test', fold) \n",
    "        if i == CFG['epochs']:\n",
    "            save_model(model, 'last', fold)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, criterion,data_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        val_loss = 0\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        \n",
    "        for x, y in data_loader:\n",
    "            \n",
    "            x = x.to(device).type(torch.float32)\n",
    "            y = y.to(device).type(torch.float32)            \n",
    "            \n",
    "            z = model(x)\n",
    "            loss = criterion(z.squeeze(-1), y)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            y_true.append(y.detach().cpu().numpy())\n",
    "            y_pred.append(torch.sigmoid(z.squeeze(-1)).detach().cpu().numpy())\n",
    "    \n",
    "    y_true = np.stack(y_true)\n",
    "    y_pred = np.stack(y_pred)\n",
    "    val_auc = roc_auc_score(y_true, y_pred)\n",
    "            \n",
    "    print(\"loss is %.3f and auc is %.3f\" %(val_loss, val_auc))\n",
    "    \n",
    "    return val_auc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, name, fold):\n",
    "    path = f'models/{name}'\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    model_name = CFG['model']\n",
    "    torch.save(model.state_dict(), f'{path}/{model_name}_{fold}.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=999, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = skf.split(X=np.zeros(len(train_df)), y=train_df.loc[: ,['target']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is 92.785 and accuracy is 0.978\n",
      "loss is 51.638 and auc is 0.877\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(folds,1):\n",
    "    \n",
    "    train_dataset = MelData(df=train_df.iloc[train_idx].reset_index(drop=True), train=True, train_augmentation=transformation)\n",
    "    \n",
    "    validation_dataset = MelData(df=train_df.iloc[train_idx].reset_index(drop=True), train=False, val=True, val_augmentation=transformation)\n",
    "    \n",
    "    train_dataloader = DataLoader(dataset=train_dataset, batch_size=24, shuffle=True, num_workers=4)\n",
    "    \n",
    "    val_dataloader = DataLoader(dataset=validation_dataset, batch_size=24, shuffle=False, drop_last=True)\n",
    "    \n",
    "    model = timm.create_model(CFG['model'], pretrained=True, num_classes=1)\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    criterion.to(device)\n",
    "\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr= 0.001)\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, mode='max', patience=3, verbose=True, factor=0.2, min_lr=0.000001)\n",
    "\n",
    "    train(model, optim, criterion, scheduler, train_dataloader, val_dataloader, fold)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
